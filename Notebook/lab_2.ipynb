{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "076139b5",
   "metadata": {},
   "source": [
    "# Machine Learning Programming - PROG8245\n",
    "## Lab 2 - Data Collection and Pre-processing\n",
    "\n",
    "This notebook implements a 12-step data engineering pipeline for an e-commerce dataset. It loads, cleans, transforms, and analyzes synthetic transaction data, then merges it with a secondary metadata source to create a data dictionary. All steps include explanations and follow the assignment requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c863e3bd",
   "metadata": {},
   "source": [
    "## STEP 1: Hello, Data!\n",
    "\n",
    "Load the synthetic e-commerce CSV file and display the first 3 rows to verify the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc331f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  CustomerID         Product    Price  Quantity     Coupon  \\\n",
      "0  2019-11-07         473   VacuumCleaner  1598.86         1  WELCOME15   \n",
      "1  2018-10-08          20            Sofa  1407.86         3    save-10   \n",
      "2  2018-11-30         406  Vacuum Cleaner   622.09         7  HOLIDAY20   \n",
      "\n",
      "  Shipping_city  \n",
      "0      Hamilton  \n",
      "1     Vancouver  \n",
      "2     Kitchener  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import datetime\n",
    "from faker import Faker\n",
    "\n",
    "# Initialize Faker for Canadian data\n",
    "fake = Faker(\"en_CA\")\n",
    "\n",
    "# Define lists for synthetic data\n",
    "Products_list = [\n",
    "    'Blender', 'Refrigerator', 'Desk Chair', 'Vacuum Cleaner', 'Microwave',\n",
    "    'VacuumCleaner', 'Sofa', 'Coffee Maker', 'Air Conditioner', 'Bookshelf',\n",
    "    'Dining Table'\n",
    "]\n",
    "Coupons_list = ['SAVE10', 'WELCOME15', 'FREESHIP', 'HOLIDAY20', 'SPRING5', 'save-10', None]\n",
    "City_list = ['Toronto', 'Vancouver', 'Montreal', 'Calgary', 'Ottawa', 'Edmonton',\n",
    "             'QuebecCity', 'Winnipeg', 'Hamilton', 'Kitchener']\n",
    "\n",
    "# Define date range\n",
    "start = datetime.date(2015, 1, 1)\n",
    "end = datetime.date(2024, 6, 1)\n",
    "\n",
    "# Generate 500 rows of synthetic data\n",
    "rows = []\n",
    "for i in range(500):\n",
    "    Product = random.choice(Products_list)\n",
    "    Price = round(random.uniform(500, 2000), 2)\n",
    "    city = random.choice(City_list)\n",
    "    coupon = random.choice(Coupons_list)\n",
    "    \n",
    "    row = {\n",
    "        \"Date\": fake.date_between(start_date=start, end_date=end),\n",
    "        \"CustomerID\": fake.random_int(min=1, max=500),\n",
    "        \"Product\": Product,\n",
    "        \"Price\": Price,\n",
    "        \"Quantity\": random.randint(1, 7),\n",
    "        \"Coupon\": coupon,\n",
    "        \"Shipping_city\": city\n",
    "    }\n",
    "    rows.append(row)\n",
    "\n",
    "# Create DataFrame and save to CSV\n",
    "data = pd.DataFrame(rows)\n",
    "data.to_csv('../Data/Ecommerce2025.csv', index=False)\n",
    "\n",
    "# Display first 3 rows\n",
    "print(data.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0369d639",
   "metadata": {},
   "source": [
    "## STEP 2: Pick the Right Container\t\n",
    "I will use dictionaries beacuse my dataset has attributes and values , and dictionaries store data as key value pair. this thing will make it easy to access each field using its lable and also easy to add/remove fields later. set will be useful when we are using to store the unique items, one example such as distinct list of cities. while namedtuple is better when the data fields are fixed and unchanging. By analysing this i would prefer a dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0dd112d",
   "metadata": {},
   "source": [
    "## STEP 3: Implement Functions and Data Structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badec780",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Transaction:\n",
    "    Date: pd.Timestamp\n",
    "    CustomerID: int\n",
    "    Product: str\n",
    "    Price: float\n",
    "    Quantity: int\n",
    "    Coupon: str\n",
    "    Shipping_city: str\n",
    "    \n",
    "    def clean(self):\n",
    "        if self.Product == 'VacuumCleaner':\n",
    "            self.Product = 'Vacuum Cleaner'\n",
    "   \n",
    "        if self.Coupon == 'save-10':\n",
    "            self.Coupon = 'SAVE10'\n",
    "       \n",
    "        if self.Coupon is None or self.Coupon == '':\n",
    "            self.Coupon = 'NONE'\n",
    "        \n",
    "        if self.Shipping_city == 'QuebecCity':\n",
    "            self.Shipping_city = 'Quebec City'\n",
    "    \n",
    "    def total(self):\n",
    "        return self.Price * self.Quantity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90abe55d",
   "metadata": {},
   "source": [
    "## STEP 4: Bulk Loaded\n",
    "\n",
    "Load the CSV into a list of dictionaries for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730fea7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Date': '2019-11-07', 'CustomerID': 473, 'Product': 'Vacuum Cleaner', 'Price': 1598.86, 'Quantity': 1, 'Coupon': 'WELCOME15', 'Shipping_city': 'Hamilton'}, {'Date': '2018-10-08', 'CustomerID': 20, 'Product': 'Sofa', 'Price': 1407.86, 'Quantity': 3, 'Coupon': 'SAVE10', 'Shipping_city': 'Vancouver'}, {'Date': '2018-11-30', 'CustomerID': 406, 'Product': 'Vacuum Cleaner', 'Price': 622.09, 'Quantity': 7, 'Coupon': 'HOLIDAY20', 'Shipping_city': 'Kitchener'}]\n"
     ]
    }
   ],
   "source": [
    "# Load CSV\n",
    "data = pd.read_csv('../Data/Ecommerce2025.csv')\n",
    "ecommerce_data = data.to_dict(orient='records')\n",
    "\n",
    "# Apply cleaning \n",
    "for record in ecommerce_data:\n",
    "    trans = Transaction(\n",
    "        Date=pd.to_datetime(record['Date']),\n",
    "        CustomerID=record['CustomerID'],\n",
    "        Product=record['Product'],\n",
    "        Price=record['Price'],\n",
    "        Quantity=record['Quantity'],\n",
    "        Coupon=record['Coupon'],\n",
    "        Shipping_city=record['Shipping_city']\n",
    "    )\n",
    "    trans.clean()\n",
    "    record['Product'] = trans.Product\n",
    "    record['Coupon'] = trans.Coupon\n",
    "    record['Shipping_city'] = trans.Shipping_city\n",
    "\n",
    "# Print first 3 records to verify\n",
    "print(ecommerce_data[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c2ac19",
   "metadata": {},
   "source": [
    "## STEP 5: Quick Profiling\n",
    "\n",
    "Calculate min, max, and mean for Price and Quantity, and count unique products and cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c1163e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price - Min: 502.74 Max: 1999.87 Mean: 1253.16\n",
      "-----\n",
      "Quantity - Min: 1 Max: 7 Mean: 3.92\n",
      "-----\n",
      "Count of Unique Products: 10\n",
      "Count of Unique Cities: 10\n",
      "-----\n",
      "Unique Cities: ['Hamilton' 'Vancouver' 'Kitchener' 'Montreal' 'Winnipeg' 'Toronto'\n",
      " 'Quebec City' 'Edmonton' 'Ottawa' 'Calgary']\n",
      "-----\n",
      "Unique Products: ['Vacuum Cleaner' 'Sofa' 'Coffee Maker' 'Dining Table' 'Desk Chair'\n",
      " 'Air Conditioner' 'Microwave' 'Blender' 'Bookshelf' 'Refrigerator']\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame(ecommerce_data)\n",
    "\n",
    "min_price = data['Price'].min()\n",
    "max_price = data['Price'].max()\n",
    "mean_price = data['Price'].mean()\n",
    "print(f\"Price - Min: {min_price:.2f} Max: {max_price:.2f} Mean: {mean_price:.2f}\")\n",
    "print(\"-----\")\n",
    "\n",
    "min_quantity = data['Quantity'].min()\n",
    "max_quantity = data['Quantity'].max()\n",
    "mean_quantity = data['Quantity'].mean()\n",
    "print(f\"Quantity - Min: {min_quantity} Max: {max_quantity} Mean: {mean_quantity:.2f}\")\n",
    "print(\"-----\")\n",
    "\n",
    "unique_products_count = data['Product'].nunique()\n",
    "unique_cities_count = data['Shipping_city'].nunique()\n",
    "print(f\"Count of Unique Products: {unique_products_count}\")\n",
    "print(f\"Count of Unique Cities: {unique_cities_count}\")\n",
    "print(\"-----\")\n",
    "\n",
    "unique_cities = data['Shipping_city'].unique()\n",
    "print(\"Unique Cities:\", unique_cities)\n",
    "print(\"-----\")\n",
    "\n",
    "unique_products = data['Product'].unique()\n",
    "print(\"Unique Products:\", unique_products)\n",
    "print(\"-----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b7e4a2",
   "metadata": {},
   "source": [
    "## STEP 6: Spot the Grime\n",
    "\n",
    "Three dirty data issues identified:\n",
    "1. **Inconsistent Product Names**: 'VacuumCleaner' and 'Vacuum Cleaner' refer to the same product.\n",
    "2. **Inconsistent Coupon Codes**: 'save-10' and 'SAVE10' are the same but formatted differently.\n",
    "3. **Missing/None Coupons**: Some records have `None` or empty strings for coupons, which should be standardized to 'NONE'.\n",
    "4. **Inconsistent City Names**: 'QuebecCity' should be 'Quebec City' for consistency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e9f5b3",
   "metadata": {},
   "source": [
    "## STEP 7: Cleaning Rules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f9e6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Cleaning:\n",
      "Vacuum Cleaner count: 36\n",
      "VacuumCleaner count: 46\n",
      "save-10 count: 79\n",
      "SAVE10 count: 67\n",
      "None/empty coupon count: 92\n",
      "QuebecCity count: 50\n",
      "\n",
      "After Cleaning:\n",
      "Vacuum Cleaner count: 82\n",
      "VacuumCleaner count: 0\n",
      "save-10 count: 0\n",
      "SAVE10 count: 146\n",
      "NONE coupon count: 0\n",
      "Quebec City count: 50\n"
     ]
    }
   ],
   "source": [
    "raw_data = pd.read_csv('../Data/Ecommerce2025.csv')\n",
    "\n",
    "print(\"Before Cleaning:\")\n",
    "print(f\"Vacuum Cleaner count: {len(raw_data[raw_data['Product'] == 'Vacuum Cleaner'])}\")\n",
    "print(f\"VacuumCleaner count: {len(raw_data[raw_data['Product'] == 'VacuumCleaner'])}\")\n",
    "print(f\"save-10 count: {len(raw_data[raw_data['Coupon'] == 'save-10'])}\")\n",
    "print(f\"SAVE10 count: {len(raw_data[raw_data['Coupon'] == 'SAVE10'])}\")\n",
    "print(f\"None/empty coupon count: {len(raw_data[raw_data['Coupon'].isna() | (raw_data['Coupon'] == '')])}\")\n",
    "print(f\"QuebecCity count: {len(raw_data[raw_data['Shipping_city'] == 'QuebecCity'])}\")\n",
    "\n",
    "# After cleaning counts (using cleaned data)\n",
    "print(\"\\nAfter Cleaning:\")\n",
    "print(f\"Vacuum Cleaner count: {len(data[data['Product'] == 'Vacuum Cleaner'])}\")\n",
    "print(f\"VacuumCleaner count: {len(data[data['Product'] == 'VacuumCleaner'])}\")\n",
    "print(f\"save-10 count: {len(data[data['Coupon'] == 'save-10'])}\")\n",
    "print(f\"SAVE10 count: {len(data[data['Coupon'] == 'SAVE10'])}\")\n",
    "print(f\"NONE coupon count: {len(data[data['Coupon'] == 'NONE'])}\")\n",
    "print(f\"Quebec City count: {len(data[data['Shipping_city'] == 'Quebec City'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e7f6d5",
   "metadata": {},
   "source": [
    "## STEP 8: Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f7e7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Discount_Percent  Count\n",
      "0              0.0     76\n",
      "1              5.0     74\n",
      "2             10.0    140\n",
      "3             15.0     71\n",
      "4             20.0     71\n"
     ]
    }
   ],
   "source": [
    "# Define coupon discount mapping\n",
    "coupon_discounts = {\n",
    "    'SAVE10': 10,\n",
    "    'WELCOME15': 15,\n",
    "    'FREESHIP': 0,  \n",
    "    'HOLIDAY20': 20,\n",
    "    'SPRING5': 5,\n",
    "    'NONE': 0\n",
    "}\n",
    "data['Discount_Percent'] = data['Coupon'].map(coupon_discounts)\n",
    "\n",
    "# Verify\n",
    "print(data['Discount_Percent'].value_counts().reset_index(name='Count'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e8f8f7",
   "metadata": {},
   "source": [
    "## STEP 9: Feature Engineering\n",
    "\n",
    "Adding a \"Days_Since_Purchase\" column, calculating days from the transaction date to today (2025-09-30)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f8f9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date  CustomerID         Product    Price  Quantity     Coupon  \\\n",
      "0 2019-11-07         473  Vacuum Cleaner  1598.86         1  WELCOME15   \n",
      "1 2018-10-08          20            Sofa  1407.86         3     SAVE10   \n",
      "2 2018-11-30         406  Vacuum Cleaner   622.09         7  HOLIDAY20   \n",
      "\n",
      "  Shipping_city  Days_Since_Purchase  \n",
      "0      Hamilton                 2154  \n",
      "1     Vancouver                 2549  \n",
      "2     Kitchener                 2496  \n"
     ]
    }
   ],
   "source": [
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "\n",
    "current_date = pd.to_datetime('2025-09-30')\n",
    "data['Days_Since_Purchase'] = (current_date - data['Date']).dt.days\n",
    "# Verify new column\n",
    "print(data.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e9f9f9",
   "metadata": {},
   "source": [
    "## STEP 10: Mini-Aggregation\n",
    "\n",
    "Calculate total revenue (Price * Quantity) per shipping city using pandas groupby."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2e9fafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shipping_city\n",
      "Calgary        239538.36\n",
      "Edmonton       266903.26\n",
      "Hamilton       166577.53\n",
      "Kitchener      226744.13\n",
      "Montreal       259269.19\n",
      "Ottawa         227216.47\n",
      "Quebec City    240882.69\n",
      "Toronto        263547.24\n",
      "Vancouver      231393.03\n",
      "Winnipeg       313963.21\n",
      "Name: Total_Revenue, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate Total_Revenue\n",
    "data['Total_Revenue'] = data['Price'] * data['Quantity']\n",
    "\n",
    "# Aggregate by shipping city\n",
    "revenue_by_city = data.groupby('Shipping_city')['Total_Revenue'].sum()\n",
    "print(revenue_by_city)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e9f9fb",
   "metadata": {},
   "source": [
    "## STEP 11: Serialization Checkpoint\n",
    "\n",
    "Save the cleaned and transformed data to JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4e9f9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to JSON\n",
    "data.to_json('../Data/Ecommerce2025_cleaned.json', orient='records', date_format='iso')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e9f9fd",
   "metadata": {},
   "source": [
    "## STEP 12: Soft Interview Reflection\n",
    "\n",
    "Functions helped to make the pipeline more efficient by splitting activities like cleaning and totaling into reusable functions within the `Transaction` class. The `clean` function cleaned up inconsistencies (e.g., product names) efficiently for all records. The `total` function facilitated easy calculation of revenues. Through the use of functions, duplicated code was eliminated, debugging was simplified, and the notebook stayed organized. This modular design also facilitated easy addition of new features, like discount parsing, without the need to rewrite code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "g6e9f9fe",
   "metadata": {},
   "source": [
    "## Data Dictionary\n",
    "\n",
    "Merged from primary CSV (Ecommerce2025.csv) and secondary metadata (coupon descriptions from a hypothetical source: https://example.com/coupon_metadata),(table created with the help of AI)\n",
    "\n",
    "| Field                | Type       | Description                                                                 | Source                          |\n",
    "|----------------------|------------|-----------------------------------------------------------------------------|---------------------------------|\n",
    "| Date                 | datetime   | Date of transaction (YYYY-MM-DD)                                            | Primary CSV (synthetic)         |\n",
    "| CustomerID           | integer    | Unique customer identifier (1–500)                                          | Primary CSV (synthetic)         |\n",
    "| Product              | string     | Product purchased (e.g., Blender, Sofa)                                     | Primary CSV (synthetic)         |\n",
    "| Price                | float      | Price per unit (500–2000 CAD)                                              | Primary CSV (synthetic)         |\n",
    "| Quantity             | integer    | Number of units purchased (1–7)                                             | Primary CSV (synthetic)         |\n",
    "| Coupon               | string     | Coupon code applied (e.g., SAVE10, NONE)                                    | Primary CSV (synthetic)         |\n",
    "| Shipping_city        | string     | City of delivery (e.g., Toronto, Quebec City)                               | Primary CSV (synthetic)         |\n",
    "| Discount_Percent     | float      | Discount percentage from coupon (0–20%)                                     | Derived (Step 8, coupon mapping)|\n",
    "| Days_Since_Purchase  | integer    | Days from transaction to 2025-09-30                                        | Derived (Step 9, date diff)     |\n",
    "| Total_Revenue        | float      | Total revenue (Price * Quantity)                                           | Derived (Step 10, calculation)  |\n",
    "\n",
    "**Notes**: \n",
    "- Primary fields (Date, CustomerID, etc.) were generated synthetically using Faker.\n",
    "- \"Discount_Percent\" was created by mapping coupon codes to percentages based on a hypothetical metadata source.\n",
    "- \"Days_Since_Purch\"ase was calculated as the difference between transaction date and 2025-09-30.\n",
    "- \"Total_Revenue\" was computed as Price * Quantity."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
